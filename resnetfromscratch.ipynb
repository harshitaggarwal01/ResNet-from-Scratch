{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnetfromscratch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3ypNsHdY6Ce"
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import AveragePooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.convolutional import ZeroPadding2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import add\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm3-kzDwq4V7"
      },
      "source": [
        "**data** is the input to the residual module\n",
        "\n",
        "**K** is the number of filters learnt by the final layer , the first two layers will learn K/4\n",
        "\n",
        "**stride** parameter controls the stride of convolution and will help reduce spatial dimensions without max pooling\n",
        "\n",
        "**chanDim** will define the axis which will perform batch normalization\n",
        "\n",
        "**red** (short for reduce) controls whether we are reducing spatial dimensions or not\n",
        "\n",
        "**reg** (short for regularization) controls regularization strength applied to the layers\n",
        "\n",
        "**bnEps** i used to control the ε epsilon which is used to avoid \"division by zero\" errors while normalizing input\n",
        "\n",
        "**bnMom** is to control momentum for moving average"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYqoOmQkaWBQ"
      },
      "source": [
        "'''\n",
        "data is the input to the residual module\n",
        "K is the number of filters learnt by the final layer , the first two layers will learn K/4\n",
        "stride parameter controls the stride of convolution and will help reduce spatial dimensions without max pooling\n",
        "chanDim will define the axis which will perform batch normalization\n",
        "red (short for reduce) controls whether we are reducing spatial dimensions or not\n",
        "reg (short for regularization) controls regularization strength applied to the layers\n",
        "bnEps i used to control the ε epsilon which is used to avoid \"division by zero\" errors while normalizing input\n",
        "bnMom is to control momentum for moving average\n",
        "'''\n",
        "class ResNet:\n",
        "  @staticmethod\n",
        "  def residual_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "    \n",
        "    #initialize the (identity) shortcut (connection), which is really just a reference to the input data\n",
        "    shortcut = data\n",
        "\n",
        "    #CONV layer utilises 1x1 convolutions by K/4 filters. Notice that the bias term is turned off\n",
        "    bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
        "    act1 = Activation(\"relu\")(bn1)\n",
        "    conv1 = Conv2D(int(K * 0.25), (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "    #for the bottleneck, the second CONV layer will learn K/4 filters that are 3x3\n",
        "    bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
        "    act2 = Activation(\"relu\")(bn2)\n",
        "    conv2 = Conv2D(int(K * 0.25), (3, 3), strides=stride,padding=\"same\", use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
        "    \n",
        "    #the final block will increase dimension again and will have K 1x1 filters\n",
        "    bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
        "    act3 = Activation(\"relu\")(bn3)\n",
        "    conv3 = Conv2D(K, (1, 1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
        "\n",
        "    #checking if reducing spatial dimensions is necessary so as to avoid max pooling\n",
        "    #if we have to reduce spatial dimensions then a conv layer with stride>1 will be applied\n",
        "    if red:\n",
        "      shortcut = Conv2D(K, (1, 1), strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
        "\n",
        "    #adding shortcut and final CONV\n",
        "    x = add([conv3, shortcut])\n",
        "\n",
        "    #output of the resnet module is x\n",
        "    return x\n",
        "  \n",
        "  #defining build method\n",
        "  #note that stages and filters parameters are lists. We are stacking N residual modules on top of each other (N=stage value)\n",
        "  @staticmethod\n",
        "  def build(width , height, depth, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
        "\n",
        "    #initialize input shape to be channels last and chanDim\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "\n",
        "    #if using channels first , update input shape and chanDim\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "      inputShape = (depth, height , width)\n",
        "      chanDim = 1\n",
        "\n",
        "    #set input and apply batch normalization\n",
        "    inputs = Input(shape=inputShape)\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(inputs)\n",
        "\n",
        "    #apply conv->batch normalization->activation->pool to reduce spatial size\n",
        "    x = Conv2D(filters[0], (5, 5), use_bias=False, padding=\"same\", kernel_regularizer=l2(reg))(x)\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    #start stacking residual layers on top of each other\n",
        "    #loop over the number of stages\n",
        "    for i in range(0, len(stages)):\n",
        "      #initialize stride and apply a res module to reduce spatial size of input volumme\n",
        "      stride = (1, 1) if i == 0 else (2, 2)\n",
        "      x = ResNet.residual_module(x, filters[i+1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "      #loop over number of layers in stage\n",
        "      for j in range(0, stages[i]-1):\n",
        "        #apply resnet module\n",
        "        x = ResNet.residual_module(x, filters[i+1], (1, 1),chanDim, bnEps=bnEps, bnMom=bnMom)\n",
        "\n",
        "    #to avoid dense fully connected layers we will apply average pooling to reduce volume size to 1x1xclasses\n",
        "    #batch normalization->activation->pool\n",
        "    x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = AveragePooling2D((8, 8))(x)\n",
        "\n",
        "    #finally lets create a dense layer for total classes and then apply softmax activation to generate final probablities as output\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "\n",
        "    #create model\n",
        "    model = Model(inputs, x, name=\"resnet\")\n",
        "\n",
        "    # return the final network architecture\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2HRzHE6h1kA",
        "outputId": "2e1f14c8-2f6b-4f36-af35-b05515f4d312",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "We can now call this class to implement ResNet architecture on any deep learning project\n",
        "'''"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nWe can now call this class to implement ResNet architecture on any deep learning project\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}